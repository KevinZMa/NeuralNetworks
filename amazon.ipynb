{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b81e93f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#! pip install -U \"datasets<4.0.0\" torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "739706ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nformat:\\n{rating: int, title: str, text: str}\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "mps = torch.device(\"mps\")\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Software\", trust_remote_code=True\n",
    ")\n",
    "# TODO: download to volume\n",
    "\"\"\"\n",
    "format:\n",
    "{rating: int, title: str, text: str}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75aebafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c560a895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4880181"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"full\"][\"text\"])\n",
    "\n",
    "# linear to size of dataset\n",
    "# linear to number of params\n",
    "# linear to number of batches (not size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c2136c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  ...,  True,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[\"full\"][\"text\"][:100000]\n",
    "# X_test = dataset[\"full\"][\"text\"][200000:225000]\n",
    "\n",
    "y = torch.tensor(dataset[\"full\"][\"rating\"][:100000]) >= 4\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b896dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b75b7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def split_text(text: str) -> list[str]:\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    words = re.split(r\"\\s+\", text)\n",
    "    return words\n",
    "\n",
    "\n",
    "def add_to_bag(text: str) -> None:\n",
    "    words = split_text(text)\n",
    "    for word in words:\n",
    "        bag_of_words[word] = bag_of_words.get(word, 0) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d077ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55414\n",
      "7744\n",
      "{'not': 25914, 'game': 25327, 'app': 18654, 'fun': 12402, 'love': 12210, 'dont': 8077, 'easy': 7917, 'software': 6668, 'free': 6454, 'works': 6181, 'than': 5728, 'kindle': 5513, 'version': 5441, 'games': 5413, 'product': 5251, 'program': 5195, 'using': 4360, 'fire': 4354, 'cant': 4240, 'amazon': 4050, 'computer': 3861, 'playing': 3818, 'lot': 3785, 'download': 3446, 'didnt': 3350, 'watch': 3277, 'nice': 3262, 'windows': 3184, 'buy': 3146, 'doesnt': 3094, 'tv': 3007, 'able': 2983, 'phone': 2887, 'kids': 2810, 'recommend': 2762, 'far': 2694, 'enjoy': 2595, 'install': 2577, 'again': 2528, 'hard': 2427, 'shows': 2416, 'price': 2412, 'apps': 2194, 'support': 2173, 'worth': 2164, '5': 2164, '3': 2119, 'going': 2106, 'having': 2075, 'tax': 2068, '2': 2040, 'downloaded': 2035, 'update': 2032, 'simple': 2014, 'once': 2012, 'graphics': 2009, 'screen': 2000, 'makes': 1999, 'video': 1979, 'music': 1955, 'wish': 1905, 'tablet': 1904, 'getting': 1872, '10': 1853, 'loves': 1846, 'challenging': 1846, 'seems': 1814, 'read': 1799, 'bought': 1777, 'word': 1777, 'levels': 1765, 'trying': 1756, 'purchase': 1748, 'bit': 1743, 'user': 1730, 'service': 1711, 'puzzles': 1710, 'available': 1707, 'level': 1703, 'system': 1692, 'features': 1674, 'looking': 1672, 'stars': 1670, 'movies': 1648, 'hours': 1631, 'own': 1627, 'pc': 1622, 'awesome': 1609, 'installed': 1590, 'wont': 1582, 'lots': 1581, 'fine': 1569, 'working': 1563, 'ever': 1538, 'mcafee': 1527, 'ads': 1494, 'programs': 1486, 'purchased': 1471, 'thats': 1466, 'online': 1456}\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# fmt: off\n",
    "ignored_words = [\n",
    "    # articles\n",
    "    \"a\", \"an\", \"the\",\n",
    "    # pronouns\n",
    "    \"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\", \"my\", \"your\", \"his\", \"her\", \"its\", \"our\", \"their\",\"his\",\"her\",\"its\",\"our\",\"their\",\n",
    "    # prepositions\n",
    "    \"at\", \"in\", \"on\", \"by\", \"for\", \"with\", \"without\", \"to\", \"from\", \"of\", \"about\", \"under\", \"over\", \"through\", \"between\", \"among\", \"during\", \"before\", \"after\", \"above\", \"below\", \"up\", \"down\", \"out\", \"off\", \"into\", \"onto\", \"upon\", \"within\", \"across\", \"along\", \"around\", \"behind\", \"beside\", \"beyond\", \"inside\", \"outside\", \"toward\", \"towards\", \"underneath\", \"against\", \"beneath\", \"near\", \"next\", \"past\", \"since\", \"until\", \"via\",\n",
    "    # conjunctions\n",
    "    \"and\", \"or\", \"but\", \"so\", \"yet\", \"nor\", \"as\", \"if\", \"when\", \"while\", \"because\", \"although\", \"though\", \"unless\", \"whereas\", \"however\", \"therefore\", \"moreover\", \"furthermore\", \"nevertheless\", \"meanwhile\",\n",
    "    # common verbs\n",
    "    \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"do\", \"does\", \"did\", \"will\", \"would\", \"could\", \"should\", \"can\", \"may\", \"might\", \"must\", \"shall\", \"get\", \"got\", \"go\", \"went\", \"come\", \"came\", \"see\", \"saw\", \"know\", \"knew\", \"think\", \"thought\", \"say\", \"said\", \"tell\", \"told\", \"make\", \"made\", \"take\", \"took\", \"give\", \"gave\", \"find\", \"found\", \"use\", \"used\", \"work\", \"worked\", \"look\", \"looked\", \"seem\", \"seemed\", \"feel\", \"felt\", \"try\", \"tried\", \"leave\", \"left\", \"put\", \"set\", \"keep\", \"kept\", \"let\", \"run\", \"ran\", \"move\", \"moved\", \"live\", \"lived\", \"bring\", \"brought\", \"happen\", \"happened\", \"write\", \"wrote\", \"sit\", \"sat\", \"stand\", \"stood\", \"lose\", \"lost\", \"pay\", \"paid\", \"meet\", \"met\", \"include\", \"included\", \"continue\", \"continued\", \"turn\", \"turned\", \"follow\", \"followed\", \"want\", \"wanted\", \"need\", \"needed\", \"like\", \"liked\", \"help\", \"helped\", \"talk\", \"talked\", \"become\", \"became\", \"show\", \"showed\", \"hear\", \"heard\", \"play\", \"played\", \"run\", \"ran\", \"move\", \"moved\", \"live\", \"lived\", \"believe\", \"believed\", \"hold\", \"held\", \"bring\", \"brought\", \"happen\", \"happened\", \"write\", \"wrote\", \"provide\", \"provided\", \"sit\", \"sat\", \"stand\", \"stood\", \"lose\", \"lost\", \"pay\", \"paid\", \"meet\", \"met\", \"include\", \"included\",\n",
    "    # adverbs\n",
    "    \"very\", \"really\", \"quite\", \"just\", \"only\", \"also\", \"too\", \"so\", \"more\", \"most\", \"much\", \"many\", \"well\", \"good\", \"better\", \"best\", \"bad\", \"worse\", \"worst\", \"little\", \"less\", \"least\", \"big\", \"bigger\", \"biggest\", \"small\", \"smaller\", \"smallest\", \"long\", \"longer\", \"longest\", \"short\", \"shorter\", \"shortest\", \"high\", \"higher\", \"highest\", \"low\", \"lower\", \"lowest\", \"first\", \"last\", \"next\", \"previous\", \"new\", \"old\", \"young\", \"great\", \"right\", \"wrong\", \"true\", \"false\", \"sure\", \"probably\", \"maybe\", \"perhaps\", \"definitely\", \"certainly\", \"absolutely\", \"completely\", \"totally\", \"exactly\", \"almost\", \"nearly\", \"hardly\", \"barely\", \"quite\", \"rather\", \"pretty\", \"fairly\", \"somewhat\", \"slightly\", \"extremely\", \"incredibly\", \"amazingly\", \"surprisingly\", \"unfortunately\", \"fortunately\", \"obviously\", \"clearly\", \"apparently\", \"generally\", \"usually\", \"normally\", \"typically\", \"often\", \"sometimes\", \"rarely\", \"never\", \"always\", \"already\", \"still\", \"yet\", \"soon\", \"now\", \"then\", \"here\", \"there\", \"where\", \"everywhere\", \"anywhere\", \"somewhere\", \"nowhere\", \"how\", \"why\", \"what\", \"when\", \"who\", \"which\", \"whose\", \"whom\",\n",
    "    # numbers and quantities\n",
    "    \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\", \"first\", \"second\", \"third\", \"another\", \"other\", \"others\", \"some\", \"any\", \"all\", \"each\", \"every\", \"both\", \"either\", \"neither\", \"none\", \"few\", \"several\", \"many\", \"most\", \"much\", \"little\", \"less\", \"more\", \"enough\", \"plenty\",\n",
    "    # misc common words\n",
    "    \"thing\", \"things\", \"something\", \"anything\", \"nothing\", \"everything\", \"someone\", \"anyone\", \"everyone\", \"no\", \"yes\", \"ok\", \"okay\", \"please\", \"thanks\", \"thank\", \"welcome\", \"hello\", \"hi\", \"bye\", \"goodbye\", \"sorry\", \"excuse\", \"pardon\", \"way\", \"ways\", \"time\", \"times\", \"day\", \"days\", \"year\", \"years\", \"place\", \"places\", \"people\", \"person\", \"man\", \"woman\", \"child\", \"children\", \"life\", \"world\", \"home\", \"house\", \"work\", \"job\", \"money\", \"business\", \"company\", \"part\", \"parts\", \"number\", \"numbers\", \"group\", \"groups\", \"problem\", \"problems\", \"question\", \"questions\", \"answer\", \"answers\", \"fact\", \"facts\", \"example\", \"examples\", \"case\", \"cases\", \"point\", \"points\", \"idea\", \"ideas\", \"information\", \"data\", \"result\", \"results\", \"change\", \"changes\", \"end\", \"beginning\", \"start\", \"finish\", \"side\", \"sides\", \"hand\", \"hands\", \"eye\", \"eyes\", \"head\", \"face\", \"back\", \"front\", \"top\", \"bottom\", \"left\", \"right\", \"inside\", \"outside\", \"important\", \"different\", \"same\", \"such\", \"even\", \"still\", \"however\", \"though\", \"although\", \"since\", \"while\", \"during\", \"before\", \"after\", \"until\", \"unless\", \"because\", \"if\", \"whether\", \"that\", \"this\", \"these\", \"those\", \"there\", \"here\", \"where\", \"when\", \"how\", \"why\", \"what\", \"who\", \"which\", \"whose\", \"whom\",\n",
    "    # common contractions\n",
    "    \"ive\", \"im\",\n",
    "    # parsing-specific\n",
    "    \"\", \"br\"\n",
    "]\n",
    "# fmt: on\n",
    "\n",
    "bag_of_words = {}\n",
    "\n",
    "for observation in X:\n",
    "    add_to_bag(observation)\n",
    "\n",
    "print(len(bag_of_words))\n",
    "\n",
    "\n",
    "bag_of_words = {\n",
    "    k: v for k, v in bag_of_words.items() if v > 10 and k not in ignored_words\n",
    "}\n",
    "print(len(bag_of_words))\n",
    "bag_of_words = dict(\n",
    "    sorted(bag_of_words.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    ")\n",
    "\n",
    "\n",
    "print(bag_of_words)\n",
    "print(len(bag_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46450363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text: str, word_to_idx: dict[str, int]) -> torch.Tensor:\n",
    "    words = split_text(text)\n",
    "\n",
    "    vector = [0] * len(word_to_idx)\n",
    "\n",
    "    for word in words:\n",
    "        idx = word_to_idx.get(word)\n",
    "        if idx is not None:\n",
    "            vector[idx] += 1\n",
    "\n",
    "    return torch.tensor(vector, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def vectorize_parallel(\n",
    "    texts: list[str], word_to_idx: dict[str, int], n_jobs: int = -1\n",
    ") -> torch.Tensor:\n",
    "    vectors = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(vectorize)(text, word_to_idx) for text in texts\n",
    "    )\n",
    "    return torch.stack(vectors).to(mps)\n",
    "\n",
    "\n",
    "def preprocess(X: list[str]) -> torch.Tensor:\n",
    "    word_to_idx = {word: idx for idx, word in enumerate(bag_of_words.keys())}\n",
    "\n",
    "    return vectorize_parallel(X, word_to_idx)\n",
    "\n",
    "\n",
    "X_processed = preprocess(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd54abd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100000\n",
      "num params L1: 7575\n",
      "num params: 7956\n"
     ]
    }
   ],
   "source": [
    "print(len(bag_of_words))\n",
    "print(len(X_processed))\n",
    "\n",
    "LAYER_1, LAYER_2 = 75, 5\n",
    "\n",
    "print(\"num params L1:\", len(bag_of_words) * LAYER_1 + LAYER_1)\n",
    "num_params = len(bag_of_words) * LAYER_1 + LAYER_1 + LAYER_1 * LAYER_2 + LAYER_2 + 1\n",
    "print(\"num params:\", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec154c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=75, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=75, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/160 [00:00<?, ?it/s]W0729 15:21:25.793000 5692 torch/_inductor/utils.py:1250] [0/2] Not enough SMs to use max_autotune_gemm mode\n",
      "/Users/kevin/Workspace/aiml/kaggle/playground-series-s5e7/.venv/lib/python3.11/site-packages/torch/_inductor/codegen/mps.py:721: UserWarning: torch.compile for Metal is an early protoype and might not work as expected. For details see https://github.com/pytorch/pytorch/issues/150121\n",
      "  _warn_prototype()\n",
      "100%|██████████| 160/160 [00:03<00:00, 45.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 95.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 86.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 91.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 97.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 92.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 97.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 90.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 91.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 96.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 97.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:02<00:00, 77.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 80.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 83.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 86.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:02<00:00, 78.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 92.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 89.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 90.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:01<00:00, 84.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 37.6588 seconds\n",
      "Train Accuracy: 0.7845 (62321/80000), random guess accuracy: 0.6713\n",
      "Test Accuracy: 0.7713 (15828/20000), random guess accuracy: 0.6823\n",
      "Precision: 0.7865, Recall: 0.9123, F1: 0.8448\n",
      "{'PARAMS': 7956, 'BATCHES': 160, 'EPOCHS': 20, 'SAMPLES': 80000, 'LR': 0.001}\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    \"PARAMS\": num_params,\n",
    "    \"BATCHES\": 160,\n",
    "    \"EPOCHS\": 20,\n",
    "    \"SAMPLES\": 80000,\n",
    "    \"LR\": 0.001,\n",
    "}\n",
    "\n",
    "def run_nn():\n",
    "    # optimal params = 10% of 80000 = 8000\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(len(bag_of_words), LAYER_1), # TODO: temporary logistic\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(LAYER_1, 1),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(LAYER_2, 1),\n",
    "        nn.Sigmoid(),\n",
    "    ).to(mps)\n",
    "    # model = torch.compile(model)\n",
    "    \n",
    "    # TODO: clear model if instantiating once\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"LR\"])\n",
    "\n",
    "    n_samples = CONFIG[\"SAMPLES\"]\n",
    "    X_train, X_test = X_processed[:n_samples], X_processed[n_samples:]\n",
    "    y_train, y_test = y[:n_samples].to(mps), y[n_samples:].to(mps)\n",
    "\n",
    "    dataset = TensorDataset(X_train, y_train)\n",
    "    dataloader = DataLoader(dataset, batch_size=len(X_train) // CONFIG[\"BATCHES\"], shuffle=True)\n",
    "    # TODO: sparse tensors?\n",
    "\n",
    "    # loss_per_batch = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(CONFIG[\"EPOCHS\"]):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        for X_batch, y_batch in tqdm(dataloader):\n",
    "            # already allocated, removing to(mps) shaved 33% of time\n",
    "            X_batch, y_batch = X_batch, y_batch\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred.squeeze(), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # loss_per_batch.append(loss.item())\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_train = model(X_train).squeeze()\n",
    "        y_pred_test = model(X_test).squeeze()\n",
    "\n",
    "    # sigmoid to binary\n",
    "    train_preds = (y_pred_train >= 0.5).int()\n",
    "    test_preds = (y_pred_test >= 0.5).int()\n",
    "\n",
    "    num_true_train = (y_train == 1).sum()\n",
    "    num_true_test = (y_test == 1).sum()\n",
    "    train_acc = (train_preds == y_train.int()).float().mean()\n",
    "    test_acc = (test_preds == y_test.int()).float().mean()\n",
    "\n",
    "    # plt.xlabel(\"Batch\")\n",
    "    # plt.ylabel(\"Loss\")\n",
    "    # plt.plot(loss_per_batch)\n",
    "    # plt.show()\n",
    "    # print(\"Final loss:\", loss_per_batch[-1])\n",
    "\n",
    "    print(\n",
    "        f\"Train Accuracy: {train_acc:.4f} ({train_preds.sum()}/{len(X_train)}), random guess accuracy: {max(num_true_train, len(X_train) - num_true_train) / len(X_train):.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Test Accuracy: {test_acc:.4f} ({test_preds.sum()}/{len(X_test)}), random guess accuracy: {max(num_true_test, len(X_test) - num_true_test) / len(X_test):.4f}\"\n",
    "    )\n",
    "\n",
    "    precision = (\n",
    "        test_preds * y_test\n",
    "    ).sum() / test_preds.sum()  # true pos / predicted pos\n",
    "    recall = (test_preds * y_test).sum() / y_test.sum()  # true pos / actual pos\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "m = run_nn()\n",
    "print(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44042c5a",
   "metadata": {},
   "source": [
    "```js\n",
    "// 7749 vocab, 64 layer 1\n",
    "Final loss: 0.43634021282196045\n",
    "Train Accuracy: 0.8201 (61019/80000)\n",
    "Test Accuracy: 0.8158 (15540/20000)\n",
    "\n",
    "// 100 vocab, 104 layer 1, 20 epoch\n",
    "Final loss: 0.48798397183418274\n",
    "Train Accuracy: 0.7697 (62999/80000), random guess accuracy: 0.6713\n",
    "Test Accuracy: 0.7691 (16053/20000), random guess accuracy: 0.6823\n",
    "Precision: 0.7812, Recall: 0.9190, F1: 0.8445\n",
    "\n",
    "// -> 100 batches\n",
    "Final loss: 0.4811912477016449\n",
    "Train Accuracy: 0.7857 (62716/80000), random guess accuracy: 0.6713\n",
    "Test Accuracy: 0.7719 (15957/20000), random guess accuracy: 0.6823\n",
    "Precision: 0.7846, Recall: 0.9176, F1: 0.8459\n",
    "\n",
    "// -> 1000 batch SIZE\n",
    "Final loss: 0.45420441031455994\n",
    "Train Accuracy: 0.7831 (62935/80000), random guess accuracy: 0.6713\n",
    "Test Accuracy: 0.7722 (15991/20000), random guess accuracy: 0.6823\n",
    "Precision: 0.7842, Recall: 0.9190, F1: 0.8463\n",
    "\n",
    "// -> 78 layer 1\n",
    "Final loss: 0.4723219573497772\n",
    "Train Accuracy: 0.7814 (62978/80000), random guess accuracy: 0.6713\n",
    "Test Accuracy: 0.7721 (16049/20000), random guess accuracy: 0.6823\n",
    "Precision: 0.7831, Recall: 0.9211, F1: 0.8465\n",
    "\n",
    "\n",
    "// 75 layer 1, 5 layer 2\n",
    "Final loss: 0.47183775901794434\n",
    "Train Accuracy: 0.7830 (61135/80000), random guess accuracy: 0.6713\n",
    "Test Accuracy: 0.7702 (15633/20000), random guess accuracy: 0.6823\n",
    "Precision: 0.7894, Recall: 0.9044, F1: 0.8430\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c6b174d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 0.2101634293794632,\n",
       " 'loves': 0.14456525444984436,\n",
       " 'challenging': 0.14364777505397797,\n",
       " 'price': 0.14253783226013184,\n",
       " 'lots': 0.1363217681646347,\n",
       " 'hours': 0.13319042325019836,\n",
       " 'nice': 0.12952637672424316,\n",
       " 'video': 0.1282006949186325,\n",
       " 'simple': 0.11462029069662094,\n",
       " 'recommend': 0.11386772990226746,\n",
       " 'awesome': 0.11303697526454926,\n",
       " 'features': 0.10963192582130432,\n",
       " 'tablet': 0.10649529099464417,\n",
       " 'tv': 0.09280779957771301,\n",
       " 'easy': 0.08715014159679413,\n",
       " 'fine': 0.07629337161779404,\n",
       " 'music': 0.07285932451486588,\n",
       " 'movies': 0.07252246886491776,\n",
       " 'seems': 0.07172495126724243,\n",
       " 'phone': 0.06769392639398575,\n",
       " 'pc': 0.06720076501369476,\n",
       " 'kindle': 0.06243222579360008,\n",
       " 'system': 0.057675719261169434,\n",
       " 'works': 0.055610403418540955,\n",
       " 'programs': 0.05272933095693588,\n",
       " 'fire': 0.05243336781859398,\n",
       " 'far': 0.04720272123813629,\n",
       " 'shows': 0.046287283301353455,\n",
       " 'own': 0.04444071650505066,\n",
       " 'able': 0.044046808034181595,\n",
       " 'app': 0.04131234064698219,\n",
       " 'having': 0.03835797682404518,\n",
       " 'installed': 0.03763207048177719,\n",
       " 'kids': 0.0332944393157959,\n",
       " 'purchase': 0.03302391245961189,\n",
       " 'fun': 0.030561519786715508,\n",
       " 'enjoy': 0.030311696231365204,\n",
       " '2': 0.02841162122786045,\n",
       " 'product': 0.025538774207234383,\n",
       " 'screen': 0.02522864378988743,\n",
       " 'free': 0.019076114520430565,\n",
       " 'bought': 0.018382014706730843,\n",
       " 'word': 0.016104139387607574,\n",
       " 'support': 0.010393072851002216,\n",
       " 'read': 0.008239289745688438,\n",
       " 'watch': 0.005581939127296209,\n",
       " 'program': 0.004778339993208647,\n",
       " 'buy': 0.00027931484510190785,\n",
       " 'ever': -0.001042330521158874,\n",
       " 'going': -0.007775810547173023,\n",
       " 'computer': -0.012661227956414223,\n",
       " 'lot': -0.012936030514538288,\n",
       " '5': -0.016790131106972694,\n",
       " 'graphics': -0.017499461770057678,\n",
       " 'download': -0.02590332366526127,\n",
       " 'downloaded': -0.030489163473248482,\n",
       " 'tax': -0.03644099459052086,\n",
       " 'purchased': -0.03840862214565277,\n",
       " 'using': -0.038433801382780075,\n",
       " 'makes': -0.03843605890870094,\n",
       " 'software': -0.0392284132540226,\n",
       " 'level': -0.0397302508354187,\n",
       " 'games': -0.04417126625776291,\n",
       " 'once': -0.044400203973054886,\n",
       " '3': -0.05128239840269089,\n",
       " 'playing': -0.051526859402656555,\n",
       " 'levels': -0.051725368946790695,\n",
       " 'apps': -0.053739603608846664,\n",
       " 'user': -0.054917361587285995,\n",
       " 'service': -0.05504165589809418,\n",
       " 'mcafee': -0.05681467056274414,\n",
       " 'worth': -0.06571073830127716,\n",
       " 'install': -0.06574425101280212,\n",
       " 'wont': -0.06742015480995178,\n",
       " 'trying': -0.07083653658628464,\n",
       " 'version': -0.07403157651424408,\n",
       " 'amazon': -0.07676041126251221,\n",
       " 'windows': -0.07875488698482513,\n",
       " 'puzzles': -0.07982382923364639,\n",
       " 'thats': -0.08817505836486816,\n",
       " 'game': -0.09660017490386963,\n",
       " 'cant': -0.09796071797609329,\n",
       " 'again': -0.10985064506530762,\n",
       " 'stars': -0.10992433875799179,\n",
       " 'online': -0.11095890402793884,\n",
       " 'than': -0.11646825820207596,\n",
       " '10': -0.12351037561893463,\n",
       " 'bit': -0.1253504902124405,\n",
       " 'dont': -0.12743650376796722,\n",
       " 'ads': -0.1277719885110855,\n",
       " 'working': -0.13188573718070984,\n",
       " 'wish': -0.13461382687091827,\n",
       " 'looking': -0.1350407600402832,\n",
       " 'getting': -0.13532979786396027,\n",
       " 'not': -0.1448410451412201,\n",
       " 'didnt': -0.14951694011688232,\n",
       " 'available': -0.17862029373645782,\n",
       " 'hard': -0.18603797256946564,\n",
       " 'doesnt': -0.20179089903831482,\n",
       " 'update': -0.25822314620018005}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def param_to_word_mapping(model: nn.Module) -> dict[str, float]:\n",
    "    # m is something like nn.Sequential(), which is a module\n",
    "    params = list(model.parameters())\n",
    "\n",
    "    mapping = zip(bag_of_words.keys(), params[0].flatten().tolist())\n",
    "\n",
    "    return {k: v for k, v in sorted(mapping, key=lambda x: x[1], reverse=True)}\n",
    "\n",
    "param_to_word_mapping(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ac6508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = time.time()\n",
    "torch.save(m, f\"model_{tm}.pth\")\n",
    "json.dump(bag_of_words, open(f\"bag_of_words_{tm}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f83a7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.serialization.add_safe_globals([nn.Sequential, nn.Linear, nn.Sigmoid, nn.ReLU])\n",
    "# m2 = torch.load(\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caaf890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
